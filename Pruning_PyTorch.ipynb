{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2KohgDRFg8SKqtzoGxj6t"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### IMPORT\n",
        "*   `import torch` imports fundamental PyTorch library\n",
        "*   `from torch import nn` imports nn module from PyTorch that contains all building blocks to define neural networks\n",
        "*   `import torch.nn.utils.prune as prune` imports prune module that enables applying prune techniques.\n",
        "*   `import torch.nn.functional as F` this module provides more functional aproach to building neural netorks and it contains functions for activation functions, pooling operations or loss calculations.\n"
      ],
      "metadata": {
        "id": "lSsuQ0uIlmOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.utils.prune as prune\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "6_08bnxJln1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CREATE A MODEL\n",
        "*   `device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")` if GPU available then sets device to cuda or else set it to cpu\n",
        "*   `class LeNet(nn.Module):` create class LeNet of the LeNet architecture that inherits the nn module that we defined above\n",
        "*   `super(LeNet, self).__init__()` calls constructor of parent class nn.Module to initialize base module\n",
        "*   `self.conv1 = nn.Conv2d(1, 6, 5)` creates a 2D convolutional layer. 1 is no. of input channels for grayscale images. 6 is no. of output channels i.e. feature maps. 5 is size of convolutional kernel i.e. 5x5 square.\n",
        "*   `self.conv2 = nn.Conv2d(6, 16, 5)` it has 6 input channels that takes input from output of conv1 so no. of input channels should match no. of outut channels. the no. of output channels are 16 and its increased to 16 cause it allows the network to learn more complex and diverse features. the kernel size is set to 5 i.e. same as conv1 to make it 5x5.\n",
        "*   `self.fc1 = nn.Linear(16*5*5,120)` the input size is 400 i.e. 16*5*5. the input layer is first fully connected layer is flattened output from previous convolutional layer. the output size is 120 cause it determines no. of neurons in this fully connected layer.\n",
        "*   `self.fc2 = nn.Linear(120, 84)` input size set to 120 cause output of fc1 is 120. output size is set to 84\n",
        "*   `self.fc3 = nn.Linear(84, 10)` input size set to 84 cause output of fc2 is 84. output size is set to 10 that is the number of classes being used.\n",
        "*   `def forward(self, x)` its forward pass of LeNet model\n",
        "*   `x = F.max_pool2d(F.relu(self.conv1(x)),(2,2))` it applies first convolutional layer that extracts features from input images via *(self.conv1)* ReLU activation is applied to introduce non-linearity *(F.relu)* and max-pooling using *(F.max_pool2d)* with a 2x2 kernel and stride of 2\n",
        "*   `x = F.max_pool2d(F.relu(self.conv2(x)), 2)` mirrors structure of 1st layer and the only difference is that it has kernel size of 2.\n",
        "*   `x = x.view(-1, int(x.nelement()/x.shape[0]))` this flattens multi-dimensional output from convolutional layers into 1-dimensional vector. *x.view(...)* reshapes tensor x. *-1* is a placeholder for PyTorch that infers size of dimension based on other dimensions and total no. of elements. *int(x.nel../..)* calculates size of flattened dimension. *x.nelement* gives total no. of elements in tensor and *x.shape[0]* gives batch size\n",
        "*   `x = F.relu(self.fc1(x)) and F.relu(self.fc2(x))` applies 1st and 2nd fully connected layer followed by ReLU activation. the fully connected layers process flattened features to learn higher-level representations.  \n",
        "*   `return x` its final output of network\n",
        "*   `model = LeNet().to(device=device)` creates instance of the class and then moves model's parameters and buffers to specified device.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "j5y7qQiops4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "  def __init__(self): #constructor\n",
        "    super(LeNet, self).__init__()\n",
        "    # 1 input image channel, 6 output channels, 5x5 square conv kernel\n",
        "    self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "    self.fc1 = nn.Linear(16 * 5 * 5, 120) #5x5 image dimension\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "      x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "      x = x.view(-1, int(x.nelement() / x.shape[0]))\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = F.relu(self.fc2(x))\n",
        "      return x\n",
        "\n",
        "model = LeNet().to(device = device)"
      ],
      "metadata": {
        "id": "U2Qt-waTpuIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### INSPECTING MODEL\n",
        "*   `module = model.conv1` it accesses specific layer of conv1 that we have to prune\n",
        "*   `print(list(module.named_parameters()))` it prints list of trainable parameters associated with *conv1* layer of the model. it iterates through module and returns each parameter's name along with its corresponding tensors\n",
        "*   `print(list(module.named_buffers()))` it prints all non-trainable parameters i.e. buffers who store values that are updated through training but arent considered model's learnable parameters.\n"
      ],
      "metadata": {
        "id": "WUlJpOpBrzZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "module = model.conv1\n",
        "print(list(module.named_parameters()))\n",
        "print(list(module.named_buffers()))"
      ],
      "metadata": {
        "id": "18dG8gtprzyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PRUNING MODULE\n",
        "*   `prune.rando_unstructured` is pruning method where pruning is applied randomly accross all weight specified tensor without considering any specific pattern.\n",
        "*   `module` it is the conv1 that we defined before.\n",
        "*   `name = \"weight\"` this is the parameter within that module that is going to be pruned.\n",
        "*   `amount = 0.3` it indicates the percentage of connections to prune and its a float between 0 and 1.\n",
        "*   `print(list(module.named_parameters()))` pruning removes *weight* from parameters and replaces it with new parameter called *weight_orig* that stores unpruned version of tensor. *bias* doesnt get pruned.\n",
        "*   `print(list(module.named_buffers()))` pruning mask generated by pruning technique selected above is saved as module buffer named *weight_mask*\n",
        "*   `print(module.weight)` for forward pass to work without modification *weight* attribute has to be there. the pruned version of weight is stored in the attribute *weight*\n",
        "*   `print(module._forward_pre_hooks)` pruning is applied to each forward pass using PyTorch's *forward_pre_hooks*. when module is pruned, it will acquire *forward_pre_hook* for each parameter associated with gets pruned.\n",
        "*   `prune.l1_unstructured(module, name = \"bias\", amount = 3)` *l1_unstructured* means that pruning is applied individually to each element of specified tensor without considering specific pattern. this one is based on l1 norm magnitude assumes that elements with smaller magnitudes are less important and can be pruned without significantly impacting ,odels performance. we now prune *bias* to see how parameters, buffers, hooks and attributes of module change.\n",
        "*   `print(list(module.named_parameters())) and print(list(module.named_buffers())` now parameters will include both weight_orig and bias_orig. buffers will include weight_mask and bias_mask. module will now have 2 forward_pre_hooks\n",
        "\n"
      ],
      "metadata": {
        "id": "-fjLlUEDuTZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prune.random_unstructured(module, name = \"weight\", amount = 0.3)\n",
        "print(list(module.named_parameters()))"
      ],
      "metadata": {
        "id": "b7pNdi_1uT2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(module.named_buffers()))"
      ],
      "metadata": {
        "id": "9BWdO998A7_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(module.weight)"
      ],
      "metadata": {
        "id": "OCwvxK_2A8eW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(module._forward_pre_hooks)"
      ],
      "metadata": {
        "id": "ILBBG5YAA99h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prune.l1_unstructured(module, name = \"bias\", amount = 3)\n",
        "print(list(module.named_parameters()))"
      ],
      "metadata": {
        "id": "jY_kX26yBCa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(module.named_buffers()))"
      ],
      "metadata": {
        "id": "0EER4GxFBD9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(module.bias)"
      ],
      "metadata": {
        "id": "H-V-mj-qBF6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(module._forward_pre_hooks)"
      ],
      "metadata": {
        "id": "vLKujXuNBHd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ITERATIVE PRUNING\n",
        "*   `prune.ln_structured` aims to remove entire rows or columns of weight tensor in structured manner.\n",
        "*   `name = \"weight\"` specifies the parameter i.e. weight tensor that has to be pruned\n",
        "*   `amount = 0.5` sets sparsity level to 50% for pruned parameter\n",
        "*   `n = 2` pruning will be performed in a 2d structured manner\n",
        "*   `dim = 0` means that prunning will be applied along 1st dimension of weight tensor that typically correspond to output channels.\n",
        "*   `print(module.weight)` pruned version of weight stored in this attribute and printing it.\n",
        "*   `for hook in module._forward_pre_hooks.values():` iterates over values of *_forward_pre_hooks* dictionary that contains hooks registered of module object.\n",
        "*   `if hook._tensor_name == \"weight\":`checks if *_tensor_name* attribute of current hook is equal to weight. basically selects specific hook associated with weight tensor.\n",
        "*   `print(list(hook))` prints pruning history stored in hook object that provides information about pruning process\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KkBdysjwBNOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prune.ln_structured(module, name = \"weight\", amount = 0.5, n = 2, dim = 0)\n",
        "print(module.weight)"
      ],
      "metadata": {
        "id": "qM4qK44ZBNid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for hook in module._forward_pre_hooks.values():\n",
        "  if hook._tensor_name == \"weight\": #select out correct hook\n",
        "    break\n",
        "\n",
        "print(list(hook)) #pruning history in container\n"
      ],
      "metadata": {
        "id": "Wq8QBxakYMKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SERIALIZING PRUNED MODEL\n",
        "*   `print(model.state_dict().keys())` all tensors, mask buffers and original parameters used to compute pruned tensors are stored in model's *state_dict* and can be serialized easily.\n",
        "\n"
      ],
      "metadata": {
        "id": "QPmAtcRlfkA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.state_dict().keys())"
      ],
      "metadata": {
        "id": "vkPceYrPfkaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### REMOVING PRUNING RE-PARAMETRIZATION\n",
        "\n",
        "> to make pruning permanent, remove re-parametrization in terms of *weight_orig* and *weight_mask* and remove *forward_pre_hook*\n",
        "\n",
        "*   `print(list(module.named_parameters())) and print(list(module.named_buffers()))` to print the parameterized and non-parameterized values\n",
        "*   `print(module.weight)` to print the weight tensor\n",
        "*   `prune.remove(module, 'weight')\n",
        "print(list(module.named_parameters()))` *prune.remove* is a function to remove re-parametrization from the mentioned module and parameter *weight*\n",
        "*   `print(list(module.named_buffers()))` to print the buffers and check if the function did remove it.\n"
      ],
      "metadata": {
        "id": "wcXP83dfy2kY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(module.named_parameters()))"
      ],
      "metadata": {
        "id": "DjI4xOlVy24X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(module.named_buffers()))"
      ],
      "metadata": {
        "id": "3JQvDnsx09RE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(module.weight)"
      ],
      "metadata": {
        "id": "HaIlk8D01j4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prune.remove(module, 'weight')\n",
        "print(list(module.named_parameters()))"
      ],
      "metadata": {
        "id": "Ngk-F1A21oQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(module.named_buffers()))"
      ],
      "metadata": {
        "id": "IaDhanrc3emk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PRUNING MULTIPLE PARAMETERS IN A MODEL\n",
        "*   `new_model = LeNet()` creating instance of LeNet model\n",
        "*   `for name, module in new_model.named_modules():` iterates through all layers within the model. *name* holds name of current model. *module* holds actual module object.\n",
        "*   `if isinstance(module, torch.nn.Conv2d):` checks if current module is 2d convolutional layer or not\n",
        "*   `prune.l1_unstructured(module, name='weight', amount=0.2)` this removes smallest 20% of connections i.e. weights in convolutional layer based on their absolute magnitude so connections with least impact are removed\n",
        "*   `elif isinstance(module, torch.nn.Linear):` checks if current module is fully connected linear layer\n",
        "*   `prune.l1_unstructured(module, name='weight', amount=0.2)` if linear layer then apply l1 unstructured pruning to layer's weights, removing smallest 40% of connections.\n",
        "*   `print(dict(new_model.named_buffers()).keys())` helps verify that pruning process has created pruning masks for each layer. pruning masks are binary tensors (0s and 1s) that indicate which connections are kept (1) and which are pruned (0)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PqiQKvYw3g60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = LeNet()\n",
        "for name, module in new_model.named_modules():\n",
        "    # prune 20% of connections in all 2D-conv layers\n",
        "    if isinstance(module, torch.nn.Conv2d):\n",
        "        prune.l1_unstructured(module, name='weight', amount=0.2)\n",
        "    # prune 40% of connections in all linear layers\n",
        "    elif isinstance(module, torch.nn.Linear):\n",
        "        prune.l1_unstructured(module, name='weight', amount=0.4)\n",
        "\n",
        "print(dict(new_model.named_buffers()).keys())  # to verify that all masks exist"
      ],
      "metadata": {
        "id": "Q3nAV-TO3hTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GLOBAL PRUNING\n",
        "*   `model = LeNet()` creates instanc of LeNet model\n",
        "*   `parameters_to_prune=(..)` defines a tuple that contains all the layers of the module and its parameters that has to be pruned.\n",
        "*   `prune.global_unstructured(..)` method to apply pruning globally across all parameters specified.\n",
        "*   `pruning_method = prune.L1Unstructured` we are using L1 unstructured pruning method that basically removes individual weights based on their absolute magnitude.\n",
        "*   `amount=0.2` 20% of weights should be pruned globally accross all specified parameters.\n"
      ],
      "metadata": {
        "id": "xXDI1gH_lDXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LeNet()\n",
        "\n",
        "parameters_to_prune = (\n",
        "    (model.conv1, 'weight'),\n",
        "    (model.conv2, 'weight'),\n",
        "    (model.fc1, 'weight'),\n",
        "    (model.fc2, 'weight'),\n",
        "    (model.fc3, 'weight'),\n",
        ")\n",
        "\n",
        "prune.global_unstructured(\n",
        "    parameters_to_prune.\n",
        "    pruning_method = prune.L1Unstructured,\n",
        "    amount = 0.2,\n",
        ")"
      ],
      "metadata": {
        "id": "py7IY5QblDw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CHECKING SPARSITY AT EACH LAYER AND GLOBALLY\n",
        "\n",
        "> here sparsity refers to percentage of weights that have been set to 0. higher sparsity means more weights have been pruned.\n",
        "\n",
        "*   the calculation of sparsity in layers is calculated by first getting total no. of elements in weight tensor then divide no. of zero weights by total no. of weights and multiplied by 100 to get sparsity percentage.\n",
        "*   to calculate global sparsity it sums up no. of zero weights accross all specified layers and divides it by total no.s of weights in these layers to calculate overall global sparsity.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ToT6stNMq5oO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "    \"Sparsity in conv1.weight: {:.2f}%\".format(\n",
        "        100. * float(torch.sum(model.conv1.weight == 0))\n",
        "        / float(model.conv1.weight.nelement())\n",
        "    )\n",
        ")\n",
        "print(\n",
        "    \"Sparsity in conv2.weight: {:.2f}%\".format(\n",
        "        100. * float(torch.sum(model.conv2.weight == 0))\n",
        "        / float(model.conv2.weight.nelement())\n",
        "    )\n",
        ")\n",
        "print(\n",
        "    \"Sparsity in fc1.weight: {:.2f}%\".format(\n",
        "        100. * float(torch.sum(model.fc1.weight == 0))\n",
        "        / float(model.fc1.weight.nelement())\n",
        "    )\n",
        ")\n",
        "print(\n",
        "    \"Sparsity in fc2.weight: {:.2f}%\".format(\n",
        "        100. * float(torch.sum(model.fc2.weight == 0))\n",
        "        / float(model.fc2.weight.nelement())\n",
        "    )\n",
        ")\n",
        "print(\n",
        "    \"Sparsity in fc3.weight: {:.2f}%\".format(\n",
        "        100. * float(torch.sum(model.fc3.weight == 0))\n",
        "        / float(model.fc3.weight.nelement())\n",
        "    )\n",
        ")\n",
        "print(\n",
        "    \"Global sparsity: {:.2f}%\".format(\n",
        "        100. * float(\n",
        "            torch.sum(model.conv1.weight == 0)\n",
        "            + torch.sum(model.conv2.weight == 0)\n",
        "            + torch.sum(model.fc1.weight == 0)\n",
        "            + torch.sum(model.fc2.weight == 0)\n",
        "            + torch.sum(model.fc3.weight == 0)\n",
        "        )\n",
        "        / float(\n",
        "            model.conv1.weight.nelement()\n",
        "            + model.conv2.weight.nelement()\n",
        "            + model.fc1.weight.nelement()\n",
        "            + model.fc2.weight.nelement()\n",
        "            + model.fc3.weight.nelement()\n",
        "        )\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "HSGnSGeSq5Jx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}